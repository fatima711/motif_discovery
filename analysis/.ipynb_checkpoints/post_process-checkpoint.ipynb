{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "from pg import IntegrityError\n",
    "\n",
    "from pg import DB\n",
    "db = DB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating database table to store sample scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.query(\"\"\"create table samples_scores_mini(\n",
    "         size integer,\n",
    "         average_score float,\n",
    "         tt_average_score float\n",
    "        )\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting samples scores into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size:10_samples:1000.pkl\n",
      "CPU times: user 5.26 ms, sys: 2.26 ms, total: 7.52 ms\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for sample_file_name in sample_file_names:\n",
    "    print(sample_file_name)\n",
    "    size = int(re.search(r'\\d+', sample_file_name).group())\n",
    "    sample = pandas.read_pickle(open( \"../files/intermediates/samples/\"+sample_file_name, \"rb\" ))\n",
    "    sample_df =pandas.DataFrame(sample)\n",
    "    pandas.DataFrame(sample)\n",
    "    for i, row in enumerate(sample_df[\"average_scores\"]):\n",
    "        do_not_print = db.insert('samples_scores',\n",
    "                             size = size,\n",
    "                             average_score = sample_df[\"average_scores\"][i],\n",
    "                             tt_average_score = sample_df[\"tt_average_scores\"][i]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating database table to store motif scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.query(\"\"\"create table motif_average_scores_mini(\n",
    "         motif_string varchar primary key,\n",
    "         proteins_length integer,\n",
    "         average_score float,\n",
    "         tt_average_score float,\n",
    "         shuffled_proteins_length integer,\n",
    "         shuffled_average_score float,\n",
    "         tt_shuffled_average_score float\n",
    "        )\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting motif scores into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numJobs:100000_jobNumber:10.pkl\n",
      "ERROR:  duplicate key value violates unique constraint \"motif_average_scores_pkey\"\n",
      "DETAIL:  Key (motif_string)=(aaaac.aa) already exists.\n",
      "\n",
      "CPU times: user 2.46 ms, sys: 1.56 ms, total: 4.01 ms\n",
      "Wall time: 3.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "motif_scores_file_names = listdir(\"../files/motif_scores/\")\n",
    "\n",
    "try:\n",
    "    for motif_scores_file_name in motif_scores_file_names:\n",
    "        print(motif_scores_file_name)\n",
    "        motif_scores = pandas.read_pickle(open( \"../files/motif_scores/\"+motif_scores_file_name, \"rb\" ))\n",
    "        motif_scores_df =pandas.DataFrame(motif_scores)\n",
    "    #     pandas.DataFrame(sample)\n",
    "        for i, row in enumerate(motif_scores_df[\"average_scores\"]):\n",
    "    #         print(motif_scores_df.index[i], motif_scores_df[\"motif_subgraph_size\"][i], motif_scores_df[\"average_scores\"][i])\n",
    "            do_not_print = db.insert('motif_average_scores',\n",
    "                                 motif_string = motif_scores_df.index[i],\n",
    "                                 proteins_length = motif_scores_df[\"motif_subgraph_size\"][i],\n",
    "                                 average_score = motif_scores_df[\"average_scores\"][i],\n",
    "                                 tt_average_score = motif_scores_df[\"average_tt_scores\"][i],\n",
    "                                 shuffled_proteins_length = motif_scores_df[\"motif_shuffled_subgraph_size\"][i],\n",
    "                                 shuffled_average_score = motif_scores_df[\"shuffled_average_scores\"][i],\n",
    "                                 tt_shuffled_average_score = motif_scores_df[\"shuffled_average_tt_scores\"][i]\n",
    "                                )\n",
    "except IntegrityError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding collumns for p_values into the motifs scores table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.query(\"ALTER TABLE motif_average_scores_mini ADD COLUMN p_value float;\")\n",
    "db.query(\"ALTER TABLE motif_average_scores_mini ADD COLUMN shuffled_p_value float;\")\n",
    "db.query(\"ALTER TABLE motif_average_scores_mini ADD COLUMN tt_p_value float;\")\n",
    "db.query(\"ALTER TABLE motif_average_scores_mini ADD COLUMN tt_shuffled_p_value float;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating p-values for motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 551 µs, sys: 663 µs, total: 1.21 ms\n",
      "Wall time: 686 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_values_file_names = listdir(\"../files/intermediates/p_values/\")\n",
    "for p_values_file in p_values_file_names:\n",
    "    p_values = pandas.read_pickle(open( \"files/intermediates/p_values/\"+p_values_file, \"rb\" ))\n",
    "    p_values_df =pandas.DataFrame(p_values)\n",
    "    print(\"dod\")\n",
    "    for i, row in enumerate(p_values_df.index):\n",
    "        do_not_print = db.query(\"UPDATE motif_average_scores SET p_value = '\" + str(p_values_df['motif_p_value'][row]) + \"', shuffled_p_value = '\" + str(p_values_df['motif_shuffled_p_value'][row]) + \"', tt_p_value = '\" + str(p_values_df['motif_tt_p_value'][row]) + \"', tt_shuffled_p_value = '\" +str(p_values_df['motif_shuffled_tt_p_value'][row]) +  \"' WHERE motif_string  = '\" + str(row) + \"'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peeking into p_values. \n",
    "\n",
    "NaN values represent entries where the p-value was not calculated because the score was not calculated since the subgraph was bigger than our cut off size. If both the subgraph and subgraph of the shuffled results are bigger than cutoff value the motif is not even in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e1503c633759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p_values' is not defined"
     ]
    }
   ],
   "source": [
    "pandas.DataFrame(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
